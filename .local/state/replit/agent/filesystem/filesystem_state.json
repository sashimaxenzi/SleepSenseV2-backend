{"file_contents":{"pyproject.toml":{"content":"[project]\nname = \"python-template\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"Your Name <you@example.com>\"]\nrequires-python = \">=3.11\"\ndependencies = [\n    \"joblib>=1.5.2\",\n    \"numpy>=2.3.5\",\n    \"pandas>=2.3.3\",\n    \"scikit-learn>=1.7.2\",\n]\n","size_bytes":247},"app.py":{"content":"# app.py\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nimport joblib\nimport numpy as np\nimport pandas as pd\n\napp = FastAPI(title=\"SleepQuality Recommendation API\")\n\n# Load model (pipeline includes preprocessing)\nmodel = joblib.load(\"models/sleep_quality_decision_tree.pkl\")\n\nclass UserInput(BaseModel):\n    age: int\n    gender: str\n    daily_steps: float = None\n    physical_activity_minutes: float = None\n    screen_time_minutes: float = None\n    stress_level: float = None\n    bmi_category: str = None\n    # add other optional fields if in your dataset\n\n@app.get(\"/health\")\ndef health():\n    return {\"status\": \"ok\"}\n\n@app.post(\"/predict\")\ndef predict(data: UserInput):\n    # Convert input to dataframe\n    input_df = pd.DataFrame([data.dict()])\n\n    # Use model pipeline to predict\n    pred = model.predict(input_df)[0]\n    pred_proba = None\n    try:\n        proba = model.predict_proba(input_df)[0]\n        pred_proba = max(proba)\n    except Exception:\n        pred_proba = None\n\n    label = \"Good\" if pred == 1 else \"Poor\"\n\n    # Feature importances or simple explanation (for DecisionTree pipeline)\n    explanation = {}\n    try:\n        # Attempt to extract feature importances from the tree\n        clf = model.named_steps['clf']\n        preproc = model.named_steps['preprocessor']\n        # Get transformed feature names\n        num_cols = preproc.transformers_[0][2]\n        cat_cols = preproc.transformers_[1][2]\n        # This is approximate; for production create exact feature names list saved during training.\n        explanation['note'] = \"Top contributing features are available from model.feature_importances_. Exact names require saved feature mapping.\"\n        explanation['feature_importances'] = clf.feature_importances_.tolist()\n    except Exception as e:\n        explanation['note'] = \"Feature importance not available in this deployment: \" + str(e)\n\n    # Generate simple rule-based recommendations (mapping)\n    recs = []\n    # Example rules (these are suggestions; tune to your tree's findings)\n    if data.stress_level is not None and data.stress_level >= 7:\n        recs.append(\"High stress detected: try relaxation techniques (10 min mindfulness), avoid screens 1 hr before bed.\")\n    if data.screen_time_minutes is not None and data.screen_time_minutes >= 90:\n        recs.append(\"High screen time: reduce screen exposure 60 minutes before bedtime.\")\n    if (data.daily_steps is not None) and (data.daily_steps < 4000):\n        recs.append(\"Low daily steps: try a short walk or light exercise during the day.\")\n    if not recs:\n        recs.append(\"Maintain your current routines: keep consistent bedtime and healthy lifestyle habits.\")\n\n    response = {\n        \"prediction\": label,\n        \"confidence\": float(pred_proba) if pred_proba is not None else None,\n        \"recommendations\": recs,\n        \"explanation\": explanation\n    }\n    return response","size_bytes":2896},"main.py":{"content":"","size_bytes":0},"train_model.py":{"content":"# train_model.py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport joblib\n\n# === LOAD DATA ===\ndf = pd.read_csv(\"data/sleep_data.csv\")  # replace with your filename\n\n# === BASIC CLEANING (edit as needed) ===\n# Example assumed column names: 'sleep_quality','age','gender','daily_steps','physical_activity_minutes','screen_time_minutes','stress_level','bmi_category'\n# Adjust the column list to actual dataset columns.\n# Drop rows without sleep_quality\ndf = df.dropna(subset=[\"sleep_quality\"])\n\n# Binarize target: Good (1) if >=6 else Poor (0)\ndf['sleep_quality_cat'] = np.where(df['sleep_quality'] >= 6, 1, 0)\n\n# Select features (adjust to actual columns). [Inference]\nfeature_cols = [\n    \"age\",\n    \"gender\",\n    \"daily_steps\",\n    \"physical_activity_minutes\",\n    \"screen_time_minutes\",\n    \"stress_level\",\n    \"bmi_category\",\n    # add other columns as present\n]\n# Keep rows that have at least one of the feature columns (or handle missing)\ndf = df[feature_cols + [\"sleep_quality_cat\"]]\n\n# Split\nX = df[feature_cols]\ny = df['sleep_quality_cat']\n\n# Identify numeric and categorical columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n\n# Preprocessing pipelines\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    # Decision Trees do not require scaling, but scaler is harmless\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numeric_transformer, numeric_cols),\n    ('cat', categorical_transformer, categorical_cols)\n])\n\n# Full pipeline with classifier\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('clf', DecisionTreeClassifier(random_state=42))\n])\n\n# Hyperparameter tuning (grid)\nparam_grid = {\n    'clf__criterion': ['gini', 'entropy'],\n    'clf__max_depth': [3, 5, 7, 9, None],\n    'clf__min_samples_split': [2, 5, 10]\n}\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)\n\ngrid = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\ngrid.fit(X_train, y_train)\n\nprint(\"Best params:\", grid.best_params_)\nbest_model = grid.best_estimator_\n\n# Evaluate\ny_pred = best_model.predict(X_test)\nprint(classification_report(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Save model\njoblib.dump(best_model, \"models/sleep_quality_decision_tree.pkl\")\nprint(\"Model saved to models/sleep_quality_decision_tree.pkl\")","size_bytes":3076}},"version":2}